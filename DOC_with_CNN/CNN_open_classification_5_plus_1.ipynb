{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Classification with CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'shared_lib.utils' from 'shared_lib/utils.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys, re, json, time, shutil\n",
    "import itertools, collections\n",
    "from IPython.display import display, HTML\n",
    "from collections import Counter\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.1\"))\n",
    "\n",
    "# utils.pretty_print_matrix uses Pandas. Configure float format here.\n",
    "import pandas as pd\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "# Helper libraries\n",
    "from shared_lib import utils, vocabulary, tf_embed_viz\n",
    "\n",
    "import copy\n",
    "\n",
    "# Import model\n",
    "#import cnnlm\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load SKlearn libraries\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'Data_Set/'\n",
    "PROJECT_PATH = os.getcwd()\n",
    "PROJECT_DATA = os.path.join(PROJECT_PATH, DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 0\t = alt.atheism\n",
      "class: 1\t = comp.graphics\n",
      "class: 2\t = comp.os.ms-windows.misc\n",
      "class: 3\t = comp.sys.ibm.pc.hardware\n",
      "class: 4\t = comp.sys.mac.hardware\n",
      "class: 5\t = comp.windows.x\n",
      "class: 6\t = misc.forsale\n",
      "class: 7\t = rec.autos\n",
      "class: 8\t = rec.motorcycles\n",
      "class: 9\t = rec.sport.baseball\n",
      "class: 10\t = rec.sport.hockey\n",
      "class: 11\t = sci.crypt\n",
      "class: 12\t = sci.electronics\n",
      "class: 13\t = sci.med\n",
      "class: 14\t = sci.space\n",
      "class: 15\t = soc.religion.christian\n",
      "class: 16\t = talk.politics.guns\n",
      "class: 17\t = talk.politics.mideast\n",
      "class: 18\t = talk.politics.misc\n",
      "class: 19\t = talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Get newsgroup data\n",
    "newsgroup_data_all = fetch_20newsgroups(subset = 'all', remove=('headers', 'footers', 'quotes'))\n",
    "all_data, all_labels = newsgroup_data_all.data, newsgroup_data_all.target\n",
    "\n",
    "# List of all the class labels\n",
    "label_list = list(newsgroup_data_all.target_names)\n",
    "\n",
    "# Print the class labels\n",
    "i = 0\n",
    "for label in label_list:\n",
    "    print \"class: %i\\t = %s\" %(i, label)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup_all.txt\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "f = open('./Data_Set/newsgroup_prep/newsgroup_all.txt', 'w') \n",
    "for doc in all_data:\n",
    "    # Clean up str\n",
    "    doc = utils.clean_str((doc).encode('utf-8'))\n",
    "    # remove stop words and do stemming optionaly\n",
    "    doc = utils.preprocess_stop_stem(doc, stop=True, sent=True, stem=False)\n",
    "    f.write(\"%s\\n\" %(doc))\n",
    "f.close()\n",
    "\n",
    "# RegEx or list of file names\n",
    "data_20newsgroup = os.path.join(PROJECT_DATA, 'newsgroup_prep/')\n",
    "\n",
    "corpus = PlaintextCorpusReader(data_20newsgroup, 'newsgroup_all.txt')\n",
    "\n",
    "for infile in sorted(corpus.fileids()):\n",
    "    print infile # The fileids of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 20000 words\n"
     ]
    }
   ],
   "source": [
    "V = 20000\n",
    "vocab = vocabulary.Vocabulary((utils.canonicalize_word(w) \n",
    "                               for w in utils.flatten(corpus.sents())),\n",
    "                               size = V)\n",
    "print \"Vocabulary: %d words\" % vocab.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly Select Classes:  ['comp.windows.x', 'talk.politics.mideast', 'comp.sys.ibm.pc.hardware', 'sci.crypt', 'comp.os.ms-windows.misc', 'comp.sys.mac.hardware']\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# Select training and test data based on the number of classes\n",
    "# Including randomization option\n",
    "import random\n",
    "from random import randint\n",
    "random.seed(8)\n",
    "\n",
    "num_class = 6\n",
    "randomize = True\n",
    "\n",
    "if randomize == True:\n",
    "    label_idxs = []\n",
    "    label_idxs = random.sample(range(1, 19), num_class)\n",
    "else:\n",
    "    label_idxs = range(num_class)\n",
    "\n",
    "select_classes = [label_list[i] for i in label_idxs]\n",
    "print \"Randomly Select Classes: \", select_classes\n",
    "\n",
    "newsgroups_all = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'),\n",
    "                                    categories=select_classes)\n",
    "\n",
    "all_data, all_labels = newsgroups_all.data, newsgroups_all.target\n",
    "print np.unique(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5849 docs (1.78349e+07 tokens)\n",
      "Training set: 4679 docs (14268913 tokens)\n",
      "Test set: 1170 docs (3566029 tokens)\n"
     ]
    }
   ],
   "source": [
    "doc_length = 500\n",
    "\n",
    "# Preprocess data\n",
    "# Cleaning special characters\n",
    "# Cut or pad based on document length\n",
    "all_docs = utils.preprocess_doc(all_data, length = doc_length)\n",
    "\n",
    "# Split total data set to training and test set\n",
    "train_docs, train_labels, test_docs, test_labels = utils.get_train_test_docs(all_docs, \n",
    "                                                                             all_labels, \n",
    "                                                                             split = 0.8, \n",
    "                                                                             shuffle = True)\n",
    "orig_test_labels = copy.copy(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Training Docs shape: (4679, 500) should equal to (batch_size, doc_length)\n",
      "Input Training labels shape: (4679, 6) should equal to (batch_size, num_class)\n",
      "Input Testing Docs shape: (1170, 500) should equal to (batch_size, doc_length)\n",
      "Input Testing labels shape: (1170, 6) should equal to (batch_size, num_class)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize documents and conver to ID\n",
    "# We tokenize each docs in the dataset and convert to vocab ID\n",
    "# matrix of batch_size x doc_length\n",
    "train_docs_ids = utils.docs_to_ids(train_docs, vocab)\n",
    "test_docs_ids = utils.docs_to_ids(test_docs, vocab)\n",
    "\n",
    "# Convert label to one-hot-code\n",
    "train_labels_oh = np.eye(num_class)[train_labels]\n",
    "test_labels_oh = np.eye(num_class)[test_labels]\n",
    "\n",
    "\n",
    "print \"Input Training Docs shape:\", train_docs_ids.shape, \"should equal to (batch_size, doc_length)\"\n",
    "print \"Input Training labels shape:\", train_labels_oh.shape, \"should equal to (batch_size, num_class)\"\n",
    "print \"Input Testing Docs shape:\", test_docs_ids.shape, \"should equal to (batch_size, doc_length)\"\n",
    "print \"Input Testing labels shape:\", test_labels_oh.shape, \"should equal to (batch_size, num_class)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained Google Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_google_bin(fname, vocab):\n",
    "    \"\"\"\n",
    "    Loads 300x1 word vecs from Google (Mikolov) word2vec\n",
    "    \"\"\"\n",
    "    word_vecs = {}\n",
    "    with open(fname, \"rb\") as f:\n",
    "        header = f.readline()\n",
    "        vocab_size, layer1_size = map(int, header.split())\n",
    "        print \"Google Word2vec Vocabulary Size:\", vocab_size\n",
    "        print \"Vector size:\", layer1_size\n",
    "        binary_len = np.dtype('float32').itemsize * layer1_size\n",
    "        print \"Binary Length of word vector:\", binary_len\n",
    "        for line in xrange(vocab_size):\n",
    "            word = []\n",
    "            while True: # Read 1 char a time\n",
    "                ch = f.read(1) \n",
    "                if ch == ' ': # If it is a space, a word is read, we join then to read its vector\n",
    "                    word = ''.join(word)\n",
    "                    break\n",
    "                if ch != '\\n': # If it is not \\n, grouping character\n",
    "                    word.append(ch) \n",
    "            if word in vocab.wordset: # If a word in the 20 newsgroup vocab, get its vector\n",
    "                word_vecs[word] = np.fromstring(f.read(binary_len), dtype='float32')  \n",
    "            else:\n",
    "                f.read(binary_len)\n",
    "    f.close()\n",
    "    return word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Word2vec Vocabulary Size: 3000000\n",
      "Vector size: 300\n",
      "Binary Length of word vector: 1200\n"
     ]
    }
   ],
   "source": [
    "google_word2vec = load_google_bin('./google_word2vec/GoogleNews-vectors-negative300.bin', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of vocabulary in 20newsgroup: 20000\n",
      "Total matched vocabulary from google word2vec: 16555\n",
      "--- Print a sample of google_word2vec vocabulary ---\n",
      "Word: raining \t\t Vector: [ 0.02331543  0.05004883 -0.00059891] ...\n",
      "Word: writings \t\t Vector: [ 0.18945312  0.2109375   0.20507812] ...\n",
      "Word: divinely \t\t Vector: [-0.02783203 -0.40820312 -0.01037598] ...\n",
      "Word: foul \t\t Vector: [ 0.18847656 -0.28710938  0.33007812] ...\n",
      "Word: four \t\t Vector: [ 0.0859375  -0.07275391  0.01672363] ...\n",
      "Word: gag \t\t Vector: [ 0.14648438 -0.08203125 -0.00897217] ...\n",
      "Word: prefix \t\t Vector: [ 0.34570312  0.1640625   0.11425781] ...\n",
      "Word: woods \t\t Vector: [ 0.11328125 -0.01165771 -0.20800781] ...\n",
      "Word: verses \t\t Vector: [ 0.28710938  0.15820312  0.23828125] ...\n",
      "Word: hanging \t\t Vector: [ 0.08984375  0.13769531 -0.14941406] ...\n",
      "Word: woody \t\t Vector: [ 0.08251953  0.44140625  0.07421875] ...\n"
     ]
    }
   ],
   "source": [
    "print \"Total Number of vocabulary in 20newsgroup:\", vocab.size\n",
    "print \"Total matched vocabulary from google word2vec:\", len(google_word2vec.keys())\n",
    "print \"--- Print a sample of google_word2vec vocabulary ---\"\n",
    "i = 0\n",
    "for k, v in google_word2vec.iteritems():\n",
    "    if i <= 10:\n",
    "        print \"Word: %s \\t\\t Vector: %s ...\" %(k, v[:3])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_unknown_words(google_word2vec, vocab, k=300):\n",
    "    for word in vocab.wordset:\n",
    "        if word not in google_word2vec:\n",
    "            google_word2vec[word] = np.random.uniform(-0.25,0.25,k)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of vocabulary in 20newsgroup: 20000\n",
      "Total matched vocabulary from google word2vec: 20000\n",
      "Pre-trained word2vec size (20000, 300)\n"
     ]
    }
   ],
   "source": [
    "add_unknown_words(google_word2vec, vocab, k=300)\n",
    "print \"Total Number of vocabulary in 20newsgroup:\", vocab.size\n",
    "print \"Total matched vocabulary from google word2vec:\", len(google_word2vec.keys())\n",
    "pt_word2vec = np.array(google_word2vec.values())\n",
    "print \"Pre-trained word2vec size\", pt_word2vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_length = 500 # s\n",
    "num_classes = num_class # M\n",
    "vocab_size = 20000\n",
    "embedding_size = 300 # d\n",
    "embedding_train = False # We use pretrained word2vec\n",
    "filter_sizes = [3, 4, 5]\n",
    "num_filters = 150\n",
    "l2_reg_lambda = 0.5\n",
    "dropout_prob = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders for input, output and dropout\n",
    "# x_: Document, Size: (batch, document_length) word in indice\n",
    "# y_: Classes, Size: (batch, num_of_classes)\n",
    "# dropout_keep_prob: Dropout regularization parameter\n",
    "x_ = tf.placeholder(tf.int32, [None, doc_length], name=\"x\")\n",
    "y_ = tf.placeholder(tf.float32, [None, num_classes], name=\"y\")\n",
    "dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "# Keeping track of l2 regularization loss (optional)\n",
    "l2_loss = tf.constant(0.0)\n",
    "\n",
    "# Embedding layer (Train embedding layer)\n",
    "# Need different implementation if use google pretrained word2vec\n",
    "with tf.name_scope(\"Embedding_Layer\"):\n",
    "    # The vocab to vector table for lookup (to be trained or pre-trained)\n",
    "    if embedding_train:\n",
    "        C_ = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name=\"C\")\n",
    "    else:\n",
    "        C_ = tf.placeholder(tf.float32, [vocab_size, embedding_size], name=\"C\")\n",
    "\n",
    "    # Embedding output needs to be in size: (batch, doc_length, embedding_size, 1)\n",
    "    # Lookup gives (batch, doc_length, embedding_size)\n",
    "    # Therefore, we need to expand the dimension to 4D to work with conv2d\n",
    "    embedded_out = tf.expand_dims(tf.nn.embedding_lookup(C_, x_), -1)\n",
    "\n",
    "# Create a convolution + maxpool layer for each filter size\n",
    "pooled_outputs = []\n",
    "for i, filter_size in enumerate(filter_sizes):\n",
    "    with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "\n",
    "        # Convolution Layer\n",
    "        # input shape: (batch, height(doc length, width(embedding size), channels(1) )\n",
    "        # filter shape: (filter_height, filter width(same as embedding size), in_channel, out_channels)\n",
    "        # in_channel = 1 for our data\n",
    "        # out_channel = num_filters\n",
    "        filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "\n",
    "        # To experiment with normal distribution\n",
    "        W_ = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "        b_ = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "\n",
    "        # \"VALID\" padding means no padding at edge\n",
    "        # Return shape (batch, height(doc length, width(embedding size), 1)\n",
    "        conv_ = tf.nn.conv2d(embedded_out, W_, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv\")\n",
    "\n",
    "        # Apply nonlinearity using Relu (train fasster than tanh)\n",
    "        # Return shape (batch, height(doc length, 1, 1)\n",
    "        h_ = tf.nn.relu(tf.nn.bias_add(conv_, b_), name=\"relu\")\n",
    "\n",
    "        # Maxpooling over the outputs\n",
    "        # ksize is window for pooling, we took 1 value for width direction\n",
    "        # For height, apply to each convolution steps to stripe the whole input matrix.\n",
    "        # Return shape (1, doc_length-filter_size+1, 1, 1)\n",
    "        pooled = tf.nn.max_pool(h_, \n",
    "                                ksize=[1, doc_length - filter_size + 1, 1, 1],\n",
    "                                strides=[1, 1, 1, 1], \n",
    "                                padding='VALID', \n",
    "                                name=\"pool\")\n",
    "        pooled_outputs.append(pooled)\n",
    "\n",
    "# Combine all the pooled features\n",
    "# find the total number of filters = num_of_filters * num_of_region\n",
    "# If we use [2, 3, 4] and 2 filter per region, we have 3 * 2 = 6 filters\n",
    "num_filters_total = num_filters * len(filter_sizes)\n",
    "\n",
    "# combine pooling output to feature vectors\n",
    "# h_pool_flat in shape of (batch_size, ? , num_filters_total)\n",
    "h_pool = tf.concat(pooled_outputs, 3)\n",
    "h_pool_flat = tf.reshape(h_pool, [-1, num_filters_total])\n",
    "\n",
    "# Add dropout\n",
    "with tf.name_scope(\"dropout\"):\n",
    "    h_drop = tf.nn.dropout(h_pool_flat, dropout_keep_prob)\n",
    "\n",
    "# Output Layer: Softmax\n",
    "# Final (unnormalized) scores and predictions\n",
    "# Do we need to normalize?\n",
    "with tf.name_scope(\"Output_layer\"):\n",
    "    Z_ = tf.Variable(tf.random_uniform([num_filters_total, num_classes], -1.0, 1.0), name = \"Z\")\n",
    "    b_output_ = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b_output\")\n",
    "    logits_ = tf.add(tf.matmul(h_drop, Z_), b_output_, name=\"logits\")\n",
    "\n",
    "    # L2 loss\n",
    "    l2_loss += tf.nn.l2_loss(Z_)\n",
    "    l2_loss += tf.nn.l2_loss(b_)\n",
    "\n",
    "    #scores = tf.nn.xw_plus_b(h_drop, W, b, name=\"scores\")\n",
    "    predictions_ = tf.argmax(logits_, 1, name=\"predictions\")\n",
    "\n",
    "# Calculate mean cross-entropy loss\n",
    "with tf.name_scope(\"cost_function\"):\n",
    "    per_example_losses_ = tf.nn.softmax_cross_entropy_with_logits(logits=logits_, \n",
    "                                                                 labels=y_,\n",
    "                                                                 name=\"per_example_loss\")\n",
    "    loss_ = tf.reduce_mean(per_example_losses_) + l2_reg_lambda * l2_loss\n",
    "\n",
    "# Accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_predictions_ = tf.equal(predictions_, tf.argmax(y_, 1))\n",
    "    accuracy_ = tf.reduce_mean(tf.cast(correct_predictions_, \"float\"), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"Training\"):\n",
    "    alpha_ = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "    optimizer_ = tf.train.AdagradOptimizer(alpha_)\n",
    "    #optimizer_ = tf.train.AdamOptimizer(alpha_)\n",
    "    train_step_ = optimizer_.minimize(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model (5 labeled + 1 unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./CNN_5p1_model/model\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"./CNN_5p1_model/model\")\n",
    "    print(\"Model restored.\")\n",
    "    feed_dict_train = {x_:train_docs_ids,\n",
    "                   y_:train_labels_oh,\n",
    "                   C_:pt_word2vec,\n",
    "                   dropout_keep_prob:dropout_prob}\n",
    "    train_vectors = sess.run([h_drop], feed_dict=feed_dict_train)[0]\n",
    "    feed_dict_test = {x_:test_docs_ids,\n",
    "                   y_:test_labels_oh,\n",
    "                   C_:pt_word2vec,\n",
    "                   dropout_keep_prob:dropout_prob}\n",
    "    test_vectors = sess.run([h_drop], feed_dict=feed_dict_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_vector shape:  (4679, 450)\n",
      "test_vector shape:  (1170, 450)\n",
      "train_label shape:  (4679,)\n",
      "test_label shape:  (1170,)\n"
     ]
    }
   ],
   "source": [
    "print \"train_vector shape: \", train_vectors.shape\n",
    "print \"test_vector shape: \", test_vectors.shape\n",
    "print \"train_label shape: \", train_labels.shape\n",
    "print \"test_label shape: \", test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-vs-Rest Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4679, 450)\n",
      "(3123, 450)\n",
      "(3123,)\n",
      "(936, 450)\n",
      "(936,)\n",
      "(773, 450)\n",
      "(773,)\n",
      "(1170, 450)\n",
      "(1170,)\n",
      "[1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n",
      "[1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "train_valid_cut = int(len(train_vectors)*0.8)\n",
    "valid_final_vectors=train_vectors[train_valid_cut:]\n",
    "valid_final_labels = train_labels[train_valid_cut:]\n",
    "\n",
    "train_new_vectors = train_vectors[:train_valid_cut]\n",
    "train_new_labels = train_labels[:train_valid_cut]\n",
    "\n",
    "missing_class = np.array([0])\n",
    "missing_class_idx = np.where(np.isin(train_new_labels, missing_class))[0]\n",
    "train_final_vectors = [train_new_vectors[i] for i in range(len(train_new_vectors)) if i not in missing_class_idx]\n",
    "train_final_labels = [train_new_labels[i] for i in range(len(train_new_labels)) if i not in missing_class_idx]\n",
    "\n",
    "val_missing_class_idx = np.where(np.isin(valid_final_labels, missing_class))[0]\n",
    "valid_calib_vectors = [valid_final_vectors[i] for i in range(len(valid_final_vectors)) if i not in val_missing_class_idx]\n",
    "valid_calib_labels = [valid_final_labels[i] for i in range(len(valid_final_labels)) if i not in val_missing_class_idx]\n",
    "\n",
    "\n",
    "\n",
    "print np.array(train_vectors).shape\n",
    "print np.array(train_final_vectors).shape\n",
    "print np.array(train_final_labels).shape\n",
    "\n",
    "print np.array(valid_final_vectors).shape\n",
    "print np.array(valid_final_labels).shape\n",
    "\n",
    "print np.array(valid_calib_vectors).shape\n",
    "print np.array(valid_calib_labels).shape\n",
    "\n",
    "\n",
    "print np.array(test_vectors).shape\n",
    "print np.array(test_labels).shape\n",
    "print np.unique(train_final_labels)\n",
    "print np.unique(valid_final_labels)\n",
    "print np.unique(valid_calib_labels)\n",
    "print np.unique(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1-vs-Rest SVM ---\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.557451115696\n",
      "{'estimator__kernel': 'poly', 'estimator__C': 2, 'estimator__degree': 2}\n"
     ]
    }
   ],
   "source": [
    "# Method SVM 1-vs-Rest\n",
    "clf_svc = OneVsRestClassifier(SVC(probability=True))\n",
    "clf_svc.fit(train_final_vectors, train_final_labels)\n",
    "\n",
    "parameters_SVC = {\n",
    "    \"estimator__C\": [0.5, 1, 2],\n",
    "    \"estimator__kernel\": [\"poly\",\"rbf\", \"sigmoid\", \"linear\"],\n",
    "    \"estimator__degree\":[1, 2, 3],\n",
    "}\n",
    "\n",
    "print \"--- 1-vs-Rest SVM ---\"\n",
    "mod_svc = GridSearchCV(estimator=clf_svc, param_grid=parameters_SVC, scoring='f1_macro', verbose=True)\n",
    "mod_svc.fit(valid_final_vectors, valid_final_labels)\n",
    "print mod_svc.best_score_ \n",
    "print mod_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print np.unique(train_final_labels)\n",
    "print np.unique(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_svc = OneVsRestClassifier(SVC(probability=True, \n",
    "                              kernel=mod_svc.best_params_['estimator__kernel'], \n",
    "                              C=mod_svc.best_params_['estimator__C'], \n",
    "                              degree=mod_svc.best_params_['estimator__degree']))\n",
    "\n",
    "clf_svc.fit(train_final_vectors, train_final_labels)\n",
    "\n",
    "## Calibrate prob\n",
    "sig_clf_svc = CalibratedClassifierCV(clf_svc, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf_svc.fit(valid_final_vectors, valid_final_labels)\n",
    "\n",
    "sig_clf_svc_probs = sig_clf_svc.predict_proba(test_vectors)\n",
    "\n",
    "\n",
    "# Manual Calibration\n",
    "clf_svc_probs = clf_svc.predict_proba(test_vectors)\n",
    "\n",
    "class_max_prob_lists = np.array([max(clf_svc_probs[:,val]) for val in range(len(clf_svc_probs[0]))])\n",
    "class_min_prob_lists = np.array([min(clf_svc_probs[:,val]) for val in range(len(clf_svc_probs[0]))])\n",
    "delta = class_max_prob_lists - class_min_prob_lists\n",
    "\n",
    "\n",
    "# Normalized for test vector\n",
    "scaled_calib_svc_probs = np.divide(clf_svc_probs,delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb23f3e3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(scaled_calib_svc_probs, axis = 1)\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[1 2 3 4 5]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       202\n",
      "          1       0.33      0.48      0.39       191\n",
      "          2       0.46      0.41      0.43       188\n",
      "          3       0.48      0.78      0.59       205\n",
      "          4       0.49      0.35      0.41       202\n",
      "          5       0.51      0.70      0.59       182\n",
      "\n",
      "avg / total       0.38      0.45      0.40      1170\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       202\n",
      "          1       0.24      0.71      0.35       191\n",
      "          2       0.51      0.35      0.42       188\n",
      "          3       0.71      0.55      0.62       205\n",
      "          4       0.51      0.49      0.50       202\n",
      "          5       0.85      0.53      0.66       182\n",
      "\n",
      "avg / total       0.47      0.44      0.42      1170\n",
      "\n",
      "0.450427350427\n",
      "0.435897435897\n"
     ]
    }
   ],
   "source": [
    "preds1 = clf_svc.predict(test_vectors)\n",
    "preds2 = sig_clf_svc.predict(test_vectors)\n",
    "print np.unique(preds1)\n",
    "print np.unique(preds2)\n",
    "print classification_report(test_labels,preds1)\n",
    "print classification_report(test_labels,preds2)\n",
    "print accuracy_score(test_labels,preds1)\n",
    "print accuracy_score(test_labels,preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find the new class, we select a Percentile for Probability Threshold for Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_prob_percentile_85 = np.array([np.percentile(scaled_calib_svc_probs[:,val], 90.0) \n",
    "                                     for val in range(len(scaled_calib_svc_probs[0]))])\n",
    "\n",
    "test_class_preds = np.greater_equal(scaled_calib_svc_probs,class_prob_percentile_85).astype(int)\n",
    "\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "valid_class_probs = np.multiply(scaled_calib_svc_probs, test_class_preds)\n",
    "valid_class = np.greater_equal(np.ceil(valid_class_probs),1).astype(int)\n",
    "predicted_multinomial = np.multiply(valid_class, np.unique(train_final_labels))\n",
    "predicted_test_class = np.max(predicted_multinomial,axis=1)\n",
    "\n",
    "# The true unseen class index\n",
    "unseen_class_indices = np.where(np.isin(test_labels, missing_class))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted test classes [0 1 2 3 4 5]\n",
      "train labels [1 2 3 4 5]\n",
      "Full list of original test labels [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print \"predicted test classes\", np.unique(predicted_test_class)\n",
    "print \"train labels\", np.unique(train_final_labels)\n",
    "print \"Full list of original test labels\", np.unique(orig_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "orig_valid_labels = copy.copy(valid_final_labels)\n",
    "\n",
    "missing_class_idx_test = np.where(np.isin(test_labels, missing_class))[0]\n",
    "missing_class_idx_val = np.where(np.isin(valid_final_labels, missing_class))[0]\n",
    "\n",
    "#print missing_class_idx_test\n",
    "#orig_test_labels = copy.copy(test_labels)\n",
    "for i in range(len(test_labels)): \n",
    "    if i in missing_class_idx_test:\n",
    "        test_labels[i] = 0\n",
    "        \n",
    "for i in range(len(valid_final_labels)): \n",
    "    if i in missing_class_idx_val:\n",
    "        valid_final_labels[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.18      0.55      0.27       202\n",
      "          1       0.48      0.25      0.33       191\n",
      "          2       0.51      0.29      0.37       188\n",
      "          3       0.73      0.41      0.53       205\n",
      "          4       0.59      0.32      0.41       202\n",
      "          5       0.83      0.53      0.65       182\n",
      "\n",
      "avg / total       0.55      0.39      0.42      1170\n",
      "\n",
      "0.393162393162\n"
     ]
    }
   ],
   "source": [
    "print classification_report(test_labels, predicted_test_class)\n",
    "print accuracy_score(test_labels, predicted_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83 40 17 39 18  5]\n",
      "202\n",
      "83.0 202\n",
      "0.410891089109\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(sorted(predicted_test_class[unseen_class_indices]))\n",
    "print sum(np.bincount(sorted(predicted_test_class[unseen_class_indices])))\n",
    "print float(np.bincount(sorted(predicted_test_class[unseen_class_indices]))[0]), \\\n",
    "    sum(np.isin(test_labels, missing_class).astype(int))\n",
    "print float(np.bincount(sorted(predicted_test_class[unseen_class_indices]))[0])/sum(np.isin(test_labels, \\\n",
    "                                                                                            missing_class).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3123, 450)\n",
      "(936, 450)\n",
      "(1170, 450)\n",
      "Size of the train dataframe: (3123, 451)\n",
      "Size of the test dataframe: (936, 451)\n",
      "Size of the test dataframe: (1170, 451)\n",
      "3123\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_final_vectors = np.array(train_final_vectors)\n",
    "valid_final_vectors=np.array(valid_final_vectors)\n",
    "test_vectors=np.array(test_vectors)\n",
    "print train_final_vectors.shape\n",
    "print valid_final_vectors.shape\n",
    "print test_vectors.shape\n",
    "\n",
    "\n",
    "X = train_final_vectors\n",
    "y = train_final_labels\n",
    "\n",
    "X_val = valid_final_vectors\n",
    "y_val = valid_final_labels\n",
    "\n",
    "X_test = test_vectors\n",
    "y_test = test_labels\n",
    "\n",
    "feat_cols = [ 'col'+str(i) for i in range(X.shape[1]) ]\n",
    "feat_cols_val = [ 'col'+str(i) for i in range(X_val.shape[1]) ]\n",
    "feat_cols_test = [ 'col'+str(i) for i in range(X_test.shape[1]) ]\n",
    "\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df['label'] = y\n",
    "df['label'] = df['label'].apply(lambda i: str(i))\n",
    "\n",
    "\n",
    "df_val = pd.DataFrame(X_val,columns=feat_cols_val)\n",
    "df_val['label'] = y_val\n",
    "df_val['label'] = df_val['label'].apply(lambda i: str(i))\n",
    "\n",
    "df_test = pd.DataFrame(X_test,columns=feat_cols_test)\n",
    "df_test['label'] = y_test\n",
    "df_test['label'] = df_test['label'].apply(lambda i: str(i))\n",
    "\n",
    "\n",
    "X, y = None, None\n",
    "print 'Size of the train dataframe: {}'.format(df.shape)\n",
    "print 'Size of the test dataframe: {}'.format(df_val.shape)\n",
    "print 'Size of the test dataframe: {}'.format(df_test.shape)\n",
    "\n",
    "N = df.shape[0]\n",
    "print N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Latent Semantic Analysis for dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing dimensionality reduction using LSA\n",
      "done in 0.180521s\n",
      "Explained variance of the SVD step: 74%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "print(\"Performing dimensionality reduction using LSA\")\n",
    "t0 = time()\n",
    "svd = TruncatedSVD(n_components=20)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "lsa_result = lsa.fit_transform(df[feat_cols].values)\n",
    "lsa_val = lsa.fit_transform(df_val[feat_cols].values)\n",
    "lsa_test = lsa.transform(df_test[feat_cols_test].values)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also try PCA for dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [ 0.34533632  0.06159975  0.0532317   0.04123619  0.03105905  0.02764521\n",
      "  0.0226991   0.01787195  0.01538894  0.01339306  0.01111898  0.01072564\n",
      "  0.00980379  0.00894017  0.00797221  0.0071358   0.00700101  0.0063144\n",
      "  0.00624755  0.00568554]\n",
      "Explained variation All components: 0.710406357422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "pca_result = pca.fit_transform(df[feat_cols].values)\n",
    "\n",
    "df['pca-one'] = pca_result[:,0]\n",
    "df['pca-two'] = pca_result[:,1] \n",
    "#df['pca-three'] = pca_result[:,2]\n",
    "#df['pca-four'] = pca_result[:,3]\n",
    "#df['pca-five'] = pca_result[:,4]\n",
    "\n",
    "\n",
    "print 'Explained variation per principal component: {}'.format(pca.explained_variance_ratio_)\n",
    "print 'Explained variation All components: {}'.format(sum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We will use LCA as it capture higher percentage of variation **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Models\n",
    "\n",
    "### Fit Gaussian Mixture Models of varying components and covariance matrix sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import operator\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy\n",
    "\n",
    "from sklearn import mixture\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "def GMM_fits(input_data=lsa_result, max_comp=21):\n",
    "    # Number of samples per component\n",
    "    n_samples = N\n",
    "    # Generate random sample, two components\n",
    "    np.random.seed(0)\n",
    "    X = np.array(input_data)\n",
    "    #X=np.array(pca_result_5)\n",
    "    print X.shape\n",
    "\n",
    "    bic_2 = {}\n",
    "    n_components_range = range(max_comp, max_comp+1)\n",
    "    cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "    aic_dict = {}\n",
    "    bic_dict = {}\n",
    "    lowest_bic = np.infty\n",
    "    lowest_aic = np.infty\n",
    "\n",
    "    for cv_type in cv_types:\n",
    "\n",
    "        bic = []\n",
    "        aic = []\n",
    "        for n_components in n_components_range:\n",
    "            # Fit a Gaussian mixture with EM\n",
    "            gmm = mixture.GaussianMixture(n_components=n_components,\n",
    "                                          covariance_type=cv_type, \n",
    "                                          reg_covar =1e-3,\n",
    "                                          random_state=0, \n",
    "                                          init_params='kmeans',\n",
    "                                          max_iter = 1350)\n",
    "            gmm.fit(X)\n",
    "            bic.append(gmm.bic(X))\n",
    "            aic.append(gmm.aic(X))\n",
    "            bic_2[cv_type+\"-\" + str(n_components)] = gmm.bic(X)\n",
    "            if bic[-1] < lowest_bic:\n",
    "                lowest_bic = bic[-1]\n",
    "                best_gmm = gmm\n",
    "            if aic[-1] < lowest_aic:\n",
    "                lowest_aic = aic[-1]\n",
    "\n",
    "        aic_dict[cv_type] = aic\n",
    "        bic_dict[cv_type] = bic\n",
    "\n",
    "    clf = best_gmm\n",
    "    sorted_bic_2 = sorted(bic_2.items(), key=operator.itemgetter(1))\n",
    "    return clf, bic_dict, aic_dict, sorted_bic_2, lowest_bic, lowest_aic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Plot AIC/BIC for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_selection_criteria(best_model, aic_dict, bic_dict, information_criteria = 'bic', max_comp = 21):\n",
    "    n_components_range = range(1,max_comp)\n",
    "    if information_criteria == 'bic':\n",
    "        for cv in bic_dict.keys():\n",
    "            plt.plot(n_components_range, bic_dict[cv], label=str(cv))\n",
    "            #plt.plot(n_components, [m.aic(X) for m in models], label='AIC')\n",
    "            plt.legend(loc=cv)\n",
    "            plt.xlabel('n_components_range')\n",
    "        plt.title(\"BIC plot\")\n",
    "    else:\n",
    "        for cv in aic_dict.keys():\n",
    "            plt.plot(n_components_range, aic_dict[cv], label=str(cv))\n",
    "            #plt.plot(n_components, [m.aic(X) for m in models], label='AIC')\n",
    "            plt.legend(loc=cv)\n",
    "            plt.xlabel('n_components_range')\n",
    "        plt.title(\"AIC plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3123, 20)\n"
     ]
    }
   ],
   "source": [
    "num_train_class = 5\n",
    "num_unseen_class =1\n",
    "best_lsa_model,lsa_bic_d,lsa_aic_d,sorted_lsa_bic,lowest_lsa_aic,lowest_lsa_bic = GMM_fits(input_data=lsa_result, \n",
    "                                                                                            max_comp=num_train_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the lowest AIC/BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest_BIC -105546.059982\n",
      "Lowest_AIC -98568.3420233\n",
      "Best GMM Model Parameters based on BIC <bound method GaussianMixture.get_params of GaussianMixture(covariance_type='full', init_params='kmeans', max_iter=1350,\n",
      "        means_init=None, n_components=5, n_init=1, precisions_init=None,\n",
      "        random_state=0, reg_covar=0.001, tol=0.001, verbose=0,\n",
      "        verbose_interval=10, warm_start=False, weights_init=None)>\n"
     ]
    }
   ],
   "source": [
    "print \"Lowest_BIC\", lowest_lsa_bic\n",
    "print \"Lowest_AIC\", lowest_lsa_aic  \n",
    "print \"Best GMM Model Parameters based on BIC\", best_lsa_model.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction using the lowest BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.135\n",
      "Completeness: 0.137\n",
      "V-measure: 0.136\n",
      "Adjusted Rand-Index: 0.112\n",
      "Silhouette Coefficient: 0.110\n",
      "fowlkes_mallows_score: 0.292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 599.,    0.,  790.,    0.,    0.,  433.,    0.,  609.,    0.,  692.]),\n",
       " array([ 0. ,  0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdab1aa1c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_cluster = best_lsa_model.predict(lsa_result)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(df['label'], predicted_cluster))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(df['label'], predicted_cluster))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(df['label'], predicted_cluster))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(df['label'], predicted_cluster))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(lsa_result, predicted_cluster, sample_size=1000))\n",
    "print (\"fowlkes_mallows_score: %.3f\"\n",
    "      % metrics.fowlkes_mallows_score(df['label'], predicted_cluster))\n",
    "plt.hist(predicted_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_cluster_comp(predicted_labels,actual_labels):\n",
    "    Cluster_ids = {}\n",
    "    for i in predicted_labels:\n",
    "        Cluster_ids[i] = (predicted_labels==i).nonzero()[0]\n",
    "\n",
    "    targets = np.array(actual_labels)\n",
    "    #print Cluster_ids\n",
    "    for label in Cluster_ids.keys():\n",
    "        #print type(label)\n",
    "        idx = Cluster_ids[label]\n",
    "        print \"Cluster Number\", str(label), \"Composition\", np.bincount(targets[idx])\n",
    "        print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Number 0 Composition [  0 210 236  45  60  48]\n",
      "\n",
      "\n",
      "Cluster Number 1 Composition [  0 190 158  70 293  79]\n",
      "\n",
      "\n",
      "Cluster Number 2 Composition [  0  42  38 313  25  15]\n",
      "\n",
      "\n",
      "Cluster Number 3 Composition [  0 104  94 142 103 166]\n",
      "\n",
      "\n",
      "Cluster Number 4 Composition [  0  81  97  56 150 308]\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print print_cluster_comp(predicted_labels=predicted_cluster, actual_labels=train_final_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_proba_val_labels = best_lsa_model.predict_proba(lsa_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.54516608e-034   1.78181519e-002   9.81754122e-001   2.02073751e-004\n",
      "    2.25652517e-004]\n",
      " [  3.61469385e-026   9.99488273e-001   7.87614961e-011   3.59661353e-004\n",
      "    1.52065504e-004]\n",
      " [  6.08348137e-050   1.12599729e-007   7.14523755e-021   9.99999887e-001\n",
      "    1.45813141e-019]\n",
      " ..., \n",
      " [  4.67493008e-100   8.60278925e-024   4.31068022e-068   1.00000000e+000\n",
      "    1.11049439e-064]\n",
      " [  6.00856471e-038   1.23130253e-003   1.79821093e-015   9.98768697e-001\n",
      "    1.54172647e-010]\n",
      " [  1.60983993e-042   6.66627403e-003   1.08184795e-028   9.93333726e-001\n",
      "    4.74120533e-029]]\n",
      "[ 1.  1.  1.  1.  1.]\n",
      "[[  9.54516609e-034   1.78181519e-002   9.81754122e-001   2.02073751e-004\n",
      "    2.25652517e-004]\n",
      " [  3.61469385e-026   9.99488273e-001   7.87614961e-011   3.59661353e-004\n",
      "    1.52065504e-004]\n",
      " [  6.08348137e-050   1.12599729e-007   7.14523755e-021   9.99999887e-001\n",
      "    1.45813141e-019]\n",
      " ..., \n",
      " [  4.67493009e-100   8.60278925e-024   4.31068022e-068   1.00000000e+000\n",
      "    1.11049439e-064]\n",
      " [  6.00856472e-038   1.23130253e-003   1.79821093e-015   9.98768697e-001\n",
      "    1.54172647e-010]\n",
      " [  1.60983994e-042   6.66627403e-003   1.08184795e-028   9.93333726e-001\n",
      "    4.74120533e-029]]\n"
     ]
    }
   ],
   "source": [
    "print pred_proba_val_labels\n",
    "val_gmm_class_max_prob_lists = np.array([max(pred_proba_val_labels[:,val]) for val in range(len(pred_proba_val_labels[0]))])\n",
    "val_gmm_class_min_prob_lists = np.array([min(pred_proba_val_labels[:,val]) for val in range(len(pred_proba_val_labels[0]))])\n",
    "val_gmm_delta = val_gmm_class_max_prob_lists - val_gmm_class_min_prob_lists\n",
    "\n",
    "print val_gmm_delta\n",
    "# Normalized for test vector\n",
    "scaled_gmm_val_class_probs = np.divide(pred_proba_val_labels,val_gmm_delta)\n",
    "print scaled_gmm_val_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdab496b0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(pred_proba_val_labels, axis = 1)\n",
    "#print pred_proba_test_labels[:,0]\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.20705169e-12   9.99070819e-01   6.93241586e-04   1.00000000e+00\n",
      "   3.21108037e-03]\n",
      "[[  9.54516609e-034   1.78181519e-002   9.81754122e-001   2.02073751e-004\n",
      "    2.25652517e-004]\n",
      " [  3.61469385e-026   9.99488273e-001   7.87614961e-011   3.59661353e-004\n",
      "    1.52065504e-004]\n",
      " [  6.08348137e-050   1.12599729e-007   7.14523755e-021   9.99999887e-001\n",
      "    1.45813141e-019]\n",
      " ..., \n",
      " [  4.67493009e-100   8.60278925e-024   4.31068022e-068   1.00000000e+000\n",
      "    1.11049439e-064]\n",
      " [  6.00856472e-038   1.23130253e-003   1.79821093e-015   9.98768697e-001\n",
      "    1.54172647e-010]\n",
      " [  1.60983994e-042   6.66627403e-003   1.08184795e-028   9.93333726e-001\n",
      "    4.74120533e-029]]\n",
      "[[0 0 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " ..., \n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[0 1 2 3 4 5 6 8 9]\n"
     ]
    }
   ],
   "source": [
    "class_threshold = 85.0\n",
    "val_gmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_gmm_val_class_probs[:,val], class_threshold) \n",
    "                                     for val in range(len(scaled_gmm_val_class_probs[0]))])\n",
    "\n",
    "print val_gmm_class_prob_percentile_cutoff\n",
    "\n",
    "gmm_val_class_preds = np.greater_equal(scaled_gmm_val_class_probs,val_gmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "print scaled_gmm_val_class_probs\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "val_gmm_valid_class_probs = np.multiply(scaled_gmm_val_class_probs, gmm_val_class_preds)\n",
    "val_gmm_valid_class = np.greater_equal(np.ceil(val_gmm_valid_class_probs),1).astype(int)\n",
    "print val_gmm_valid_class\n",
    "val_gmm_predicted_multinomial = np.multiply(val_gmm_valid_class, np.unique(train_final_labels))\n",
    "print np.unique(np.sum(val_gmm_predicted_multinomial, axis=1))\n",
    "gmm_predicted_val_class = np.max(val_gmm_predicted_multinomial,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163 164 152 157 158 142] [352  50 141 111 141 141]\n",
      "936 936\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(valid_final_labels), np.bincount(gmm_predicted_val_class)\n",
    "print np.sum(np.bincount(valid_final_labels)), np.sum(np.bincount(gmm_predicted_val_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Unseen Class Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composition of gmm_predicted_valid_class for true unseen class indices [57 12 28 21 27 18]\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "print \"Composition of gmm_predicted_valid_class for true unseen class indices\", np.bincount(sorted(gmm_predicted_val_class[missing_class_idx_val]))\n",
    "print sum(np.bincount(sorted(gmm_predicted_val_class[missing_class_idx_val])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.35      0.16      0.22       352\n",
      "          1       0.04      0.14      0.07        50\n",
      "          2       0.09      0.10      0.10       141\n",
      "          3       0.35      0.50      0.41       111\n",
      "          4       0.04      0.05      0.05       141\n",
      "          5       0.38      0.38      0.38       141\n",
      "\n",
      "avg / total       0.25      0.21      0.21       936\n",
      "\n",
      "[[57 62 58 52 76 47]\n",
      " [12  7 13  3 10  5]\n",
      " [28 46 14 13 21 19]\n",
      " [21  7  4 55 19  5]\n",
      " [27 21 55 19  7 12]\n",
      " [18 21  8 15 25 54]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "print classification_report(gmm_predicted_val_class, valid_final_labels)\n",
    "print confusion_matrix(gmm_predicted_val_class, valid_final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.161931818182 0.349693251534 0.221359223301\n"
     ]
    }
   ],
   "source": [
    "def calculate_unseen_class_f1score(pred_class, true_class, unseen_class_id):\n",
    "    predicted_zero_ind = (pred_class==unseen_class_id).nonzero()[0]\n",
    "    predicted_nonzero_ind = (pred_class > unseen_class_id).nonzero()[0]\n",
    "    #print np.bincount(true_class[predicted_zero_ind])[0]\n",
    "    TP = np.bincount(true_class[predicted_zero_ind])[0]\n",
    "    FP =  sum(np.bincount(true_class[predicted_zero_ind])) - TP\n",
    "    FN =  np.bincount(true_class[predicted_nonzero_ind])[0]\n",
    "    #print TP, FP, FN\n",
    "    unseen_class_precision = float(TP)/(TP+FP)\n",
    "    unseen_class_recall = float(TP)/(TP+FN)\n",
    "    unseen_class_f1 = 2*unseen_class_precision*unseen_class_recall/(unseen_class_precision+unseen_class_recall)\n",
    "    #print unseen_class_precision,unseen_class_recall,unseen_class_f1\n",
    "    return unseen_class_precision, unseen_class_recall,unseen_class_f1\n",
    "    \n",
    "pr,re,f1 = calculate_unseen_class_f1score(gmm_predicted_val_class, np.array(valid_final_labels), 0)\n",
    "print pr,re,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  59 F1 Score:  0.0239520958084\n",
      "Actual Unseen Class 163 Predicted Unseen Class 4\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  60 F1 Score:  0.0346820809249\n",
      "Actual Unseen Class 163 Predicted Unseen Class 10\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  61 F1 Score:  0.0446927374302\n",
      "Actual Unseen Class 163 Predicted Unseen Class 16\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  62 F1 Score:  0.0549450549451\n",
      "Actual Unseen Class 163 Predicted Unseen Class 19\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  63 F1 Score:  0.0534759358289\n",
      "Actual Unseen Class 163 Predicted Unseen Class 24\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  64 F1 Score:  0.0714285714286\n",
      "Actual Unseen Class 163 Predicted Unseen Class 33\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  65 F1 Score:  0.0696517412935\n",
      "Actual Unseen Class 163 Predicted Unseen Class 38\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  66 F1 Score:  0.085308056872\n",
      "Actual Unseen Class 163 Predicted Unseen Class 48\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  67 F1 Score:  0.0913242009132\n",
      "Actual Unseen Class 163 Predicted Unseen Class 56\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  68 F1 Score:  0.0873362445415\n",
      "Actual Unseen Class 163 Predicted Unseen Class 66\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  69 F1 Score:  0.092050209205\n",
      "Actual Unseen Class 163 Predicted Unseen Class 76\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  70 F1 Score:  0.111553784861\n",
      "Actual Unseen Class 163 Predicted Unseen Class 88\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  71 F1 Score:  0.12213740458\n",
      "Actual Unseen Class 163 Predicted Unseen Class 99\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  72 F1 Score:  0.130909090909\n",
      "Actual Unseen Class 163 Predicted Unseen Class 112\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  73 F1 Score:  0.130136986301\n",
      "Actual Unseen Class 163 Predicted Unseen Class 129\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  74 F1 Score:  0.144262295082\n",
      "Actual Unseen Class 163 Predicted Unseen Class 142\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  75 F1 Score:  0.140672782875\n",
      "Actual Unseen Class 163 Predicted Unseen Class 164\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  76 F1 Score:  0.139941690962\n",
      "Actual Unseen Class 163 Predicted Unseen Class 180\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  77 F1 Score:  0.146478873239\n",
      "Actual Unseen Class 163 Predicted Unseen Class 192\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  78 F1 Score:  0.154255319149\n",
      "Actual Unseen Class 163 Predicted Unseen Class 213\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  79 F1 Score:  0.173027989822\n",
      "Actual Unseen Class 163 Predicted Unseen Class 230\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  80 F1 Score:  0.175182481752\n",
      "Actual Unseen Class 163 Predicted Unseen Class 248\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  81 F1 Score:  0.190255220418\n",
      "Actual Unseen Class 163 Predicted Unseen Class 268\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  82 F1 Score:  0.200445434298\n",
      "Actual Unseen Class 163 Predicted Unseen Class 286\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  83 F1 Score:  0.20253164557\n",
      "Actual Unseen Class 163 Predicted Unseen Class 311\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  84 F1 Score:  0.211382113821\n",
      "Actual Unseen Class 163 Predicted Unseen Class 329\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  85 F1 Score:  0.221359223301\n",
      "Actual Unseen Class 163 Predicted Unseen Class 352\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  86 F1 Score:  0.221811460259\n",
      "Actual Unseen Class 163 Predicted Unseen Class 378\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  87 F1 Score:  0.224561403509\n",
      "Actual Unseen Class 163 Predicted Unseen Class 407\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  88 F1 Score:  0.239460370995\n",
      "Actual Unseen Class 163 Predicted Unseen Class 430\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  89 F1 Score:  0.244444444444\n",
      "Actual Unseen Class 163 Predicted Unseen Class 467\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  90 F1 Score:  0.249240121581\n",
      "Actual Unseen Class 163 Predicted Unseen Class 495\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  91 F1 Score:  0.253602305476\n",
      "Actual Unseen Class 163 Predicted Unseen Class 531\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  92 F1 Score:  0.258152173913\n",
      "Actual Unseen Class 163 Predicted Unseen Class 573\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  93 F1 Score:  0.261658031088\n",
      "Actual Unseen Class 163 Predicted Unseen Class 609\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  94 F1 Score:  0.267156862745\n",
      "Actual Unseen Class 163 Predicted Unseen Class 653\n"
     ]
    }
   ],
   "source": [
    "best_threshold = 0.0\n",
    "best_f1_score=0.0\n",
    "for threshold in range(50,95):\n",
    "    try:\n",
    "        val_gmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_gmm_val_class_probs[:,val], float(threshold)) \n",
    "                                             for val in range(len(scaled_gmm_val_class_probs[0]))])\n",
    "\n",
    "        #print val_gmm_class_prob_percentile_cutoff\n",
    "\n",
    "        gmm_val_class_preds = np.greater_equal(scaled_gmm_val_class_probs,val_gmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "        #print scaled_gmm_val_class_probs\n",
    "        # Predict the test label based on percental\n",
    "        # If a data is below 80% for prob of all class, it belongs to open class\n",
    "        val_gmm_valid_class_probs_dup = np.multiply(scaled_gmm_val_class_probs, gmm_val_class_preds)\n",
    "\n",
    "        val_gmm_valid_class_max_probs = np.max(val_gmm_valid_class_probs_dup, axis=1)\n",
    "        #print gmm_valid_class_max_probs\n",
    "        #print type(gmm_valid_class_probs_dup),  type(gmm_valid_class_max_probs)\n",
    "        val_temp = np.equal(val_gmm_valid_class_probs_dup , val_gmm_valid_class_max_probs.reshape(len(val_gmm_valid_class_max_probs),1))\n",
    "        val_gmm_valid_class_probs=np.multiply(val_gmm_valid_class_probs_dup,val_temp)\n",
    "        val_gmm_valid_class = np.greater_equal(np.ceil(val_gmm_valid_class_probs),1).astype(int)\n",
    "        #print val_gmm_valid_class\n",
    "        val_gmm_predicted_multinomial = np.multiply(val_gmm_valid_class, np.unique(train_final_labels))\n",
    "        #print np.unique(np.sum(val_gmm_predicted_multinomial, axis=1))\n",
    "        gmm_predicted_val_class = np.max(val_gmm_predicted_multinomial,axis=1)  \n",
    "        print np.unique(gmm_predicted_val_class), np.unique(valid_final_labels)\n",
    "        pr,re,f1 = calculate_unseen_class_f1score(gmm_predicted_val_class,valid_final_labels,0)\n",
    "        print \"Threshold: \",threshold, \"F1 Score: \", f1 \n",
    "        print \"Actual Unseen Class\", np.bincount(valid_final_labels)[0], \"Predicted Unseen Class\",np.bincount(gmm_predicted_val_class)[0]\n",
    "        # Set the threshold so that not unseen class volume is actual unseen class volume in validation set\n",
    "        unseen_class_ratio = float(np.bincount(gmm_predicted_val_class)[0])/np.bincount(valid_final_labels)[0]\n",
    "        #overall_F1_score = f1_score(gmm_predicted_val_class, valid_final_labels)\n",
    "        if f1 > best_f1_score and unseen_class_ratio < 1.1:\n",
    "\n",
    "            best_f1_score = f1\n",
    "            best_threshold = threshold\n",
    "    except:\n",
    "        print \"Threshold Too Low. No unseen class prediction\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_proba_test_labels = best_lsa_model.predict_proba(lsa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.55324906e-17   5.92594387e-04   5.38359597e-23   9.99407406e-01\n",
      "    6.11363507e-19]\n",
      " [  8.55035591e-50   9.99999999e-01   3.43314179e-33   1.49514270e-09\n",
      "    5.47343878e-14]\n",
      " [  9.08441848e-29   3.63854172e-07   9.99999620e-01   2.47056086e-14\n",
      "    1.57810823e-08]\n",
      " ..., \n",
      " [  6.70082245e-10   4.57997815e-03   9.95123392e-01   4.27734144e-07\n",
      "    2.96201580e-04]\n",
      " [  7.57528047e-28   8.63475354e-06   1.16586037e-37   9.99991365e-01\n",
      "    2.50986472e-28]\n",
      " [  8.33133430e-17   9.99999992e-01   4.25403390e-16   4.58325237e-16\n",
      "    8.24706124e-09]]\n",
      "[ 1.  1.  1.  1.  1.]\n",
      "[[  1.55324906e-17   5.92594387e-04   5.38359597e-23   9.99407406e-01\n",
      "    6.11363508e-19]\n",
      " [  8.55035592e-50   9.99999999e-01   3.43314179e-33   1.49514270e-09\n",
      "    5.47343879e-14]\n",
      " [  9.08441850e-29   3.63854172e-07   9.99999620e-01   2.47056086e-14\n",
      "    1.57810823e-08]\n",
      " ..., \n",
      " [  6.70082246e-10   4.57997815e-03   9.95123392e-01   4.27734144e-07\n",
      "    2.96201580e-04]\n",
      " [  7.57528048e-28   8.63475354e-06   1.16586037e-37   9.99991365e-01\n",
      "    2.50986472e-28]\n",
      " [  8.33133431e-17   9.99999992e-01   4.25403390e-16   4.58325237e-16\n",
      "    8.24706125e-09]]\n"
     ]
    }
   ],
   "source": [
    "print pred_proba_test_labels\n",
    "gmm_class_max_prob_lists = np.array([max(pred_proba_test_labels[:,val]) for val in range(len(pred_proba_test_labels[0]))])\n",
    "gmm_class_min_prob_lists = np.array([min(pred_proba_test_labels[:,val]) for val in range(len(pred_proba_test_labels[0]))])\n",
    "gmm_delta = gmm_class_max_prob_lists - gmm_class_min_prob_lists\n",
    "\n",
    "print gmm_delta\n",
    "# Normalized for test vector\n",
    "scaled_gmm_test_class_probs = np.divide(pred_proba_test_labels,gmm_delta)\n",
    "print scaled_gmm_test_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdab39d3950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(pred_proba_test_labels, axis = 1)\n",
    "#print pred_proba_test_labels[:,0]\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00]\n",
      " [  0.00000000e+00   9.99999999e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   9.99999620e-01   0.00000000e+00\n",
      "    0.00000000e+00]\n",
      " ..., \n",
      " [  6.70082246e-10   0.00000000e+00   9.95123392e-01   0.00000000e+00\n",
      "    2.96201580e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00]\n",
      " [  0.00000000e+00   9.99999992e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00]]\n",
      "[ 0.          1.          0.99999962 ...,  0.99512339  0.          0.99999999]\n",
      "[[0 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " ..., \n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 0 0 0]]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print best_threshold\n",
    "gmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_gmm_test_class_probs[:,val], best_threshold) \n",
    "                                     for val in range(len(scaled_gmm_test_class_probs[0]))])\n",
    "\n",
    "#print gmm_class_prob_percentile_cutoff\n",
    "\n",
    "gmm_test_class_preds = np.greater_equal(scaled_gmm_test_class_probs,gmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "#print scaled_gmm_test_class_probs\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "gmm_valid_class_probs_dup = np.multiply(scaled_gmm_test_class_probs, gmm_test_class_preds)\n",
    "print gmm_valid_class_probs_dup\n",
    "gmm_valid_class_max_probs = np.max(gmm_valid_class_probs_dup, axis=1)\n",
    "print gmm_valid_class_max_probs\n",
    "#print type(gmm_valid_class_probs_dup),  type(gmm_valid_class_max_probs)\n",
    "temp = np.equal(gmm_valid_class_probs_dup , gmm_valid_class_max_probs.reshape(len(gmm_valid_class_max_probs),1))\n",
    "gmm_valid_class_probs=np.multiply(gmm_valid_class_probs_dup,temp)\n",
    "gmm_valid_class = np.greater_equal(np.ceil(gmm_valid_class_probs),1).astype(int)\n",
    "print gmm_valid_class\n",
    "gmm_predicted_multinomial = np.multiply(gmm_valid_class, np.unique(train_final_labels))\n",
    "print np.unique(np.sum(gmm_predicted_multinomial, axis=1))\n",
    "gmm_predicted_test_class = np.max(gmm_predicted_multinomial,axis=1)\n",
    "\n",
    "# The true unseen class index\n",
    "#unseen_class_indices = np.where(np.isin(test_labels, missing_class))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202 191 188 205 202 182] [196  77 304 166 304 123]\n",
      "1170 1170\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(test_labels), np.bincount(gmm_predicted_test_class)\n",
    "print np.sum(np.bincount(test_labels)), np.sum(np.bincount(gmm_predicted_test_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27 14 43 61 46 11]\n",
      " [44 13 67 13 43 11]\n",
      " [44 16 44  6 69  9]\n",
      " [23  8 37 60 64 13]\n",
      " [34 14 58 20 50 26]\n",
      " [24 12 55  6 32 53]]\n"
     ]
    }
   ],
   "source": [
    "print confusion_matrix(test_labels, gmm_predicted_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.13      0.14       202\n",
      "          1       0.17      0.07      0.10       191\n",
      "          2       0.14      0.23      0.18       188\n",
      "          3       0.36      0.29      0.32       205\n",
      "          4       0.16      0.25      0.20       202\n",
      "          5       0.43      0.29      0.35       182\n",
      "\n",
      "avg / total       0.23      0.21      0.21      1170\n",
      "\n",
      "0.211111111111\n"
     ]
    }
   ],
   "source": [
    "print classification_report(test_labels, gmm_predicted_test_class)\n",
    "print accuracy_score(test_labels, gmm_predicted_test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unseen Class Precision, Recall F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Class Precision:  0.137755102041\n",
      "Unseen Class Recall:  0.133663366337\n",
      "Unseen Class F1 Score:  0.13567839196\n"
     ]
    }
   ],
   "source": [
    "print \"Unseen Class Precision: \", calculate_unseen_class_f1score(gmm_predicted_test_class,test_labels,0)[0]\n",
    "print \"Unseen Class Recall: \", calculate_unseen_class_f1score(gmm_predicted_test_class,test_labels,0)[1]\n",
    "print \"Unseen Class F1 Score: \", calculate_unseen_class_f1score(gmm_predicted_test_class,test_labels,0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_class_indices = (gmm_predicted_test_class==0).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.054\n",
      "Completeness: 0.057\n",
      "V-measure: 0.055\n",
      "Adjusted Rand-Index: 0.030\n",
      "Silhouette Coefficient: 0.028\n",
      "fowlkes_mallows_score: 0.206\n"
     ]
    }
   ],
   "source": [
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(lsa_test, gmm_predicted_test_class, sample_size=1000))\n",
    "print (\"fowlkes_mallows_score: %.3f\"\n",
    "      % metrics.fowlkes_mallows_score(df_test['label'], gmm_predicted_test_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Clustering Unsee Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_unseen_class_lsa= lsa_test[pred_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fowlkes_mallows_score: 0.418\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdab2101290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fowlkes_mallows_score: 0.418\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdab477fa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fowlkes_mallows_score: 0.418\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdab1e87c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fowlkes_mallows_score: 0.418\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdab3eb5fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "c_var = ['full', 'tied', 'diag', 'spherical']\n",
    "n_components=1\n",
    "models = [BayesianGaussianMixture(n_components, covariance_type=c, init_params='random').fit(predicted_unseen_class_lsa)\n",
    "          for c in c_var]\n",
    "\n",
    "for m in range(len(models)):\n",
    "    plt.title(\"Model with Covariance type: \" + str(c_var[m]))\n",
    "    plt.hist(models[m].predict(predicted_unseen_class_lsa))\n",
    "    pred_ls = models[m].predict(predicted_unseen_class_lsa)\n",
    "    print (\"fowlkes_mallows_score: %.3f\"\n",
    "      % metrics.fowlkes_mallows_score(pred_ls, orig_test_labels[pred_class_indices]))\n",
    "    plt.show()\n",
    "#gmm2_model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infinite Dirichlet Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BGMM_fits(input_data=lsa_result, cv_type='full', max_comp=21):\n",
    "    mod = BayesianGaussianMixture(n_components=max_comp, covariance_type='full', \n",
    "                                  weight_concentration_prior_type=\"dirichlet_process\", \n",
    "                                  reg_covar=0, init_params='random',\n",
    "        max_iter=1500, mean_precision_prior=.8,random_state=0)\n",
    "    X = np.array(input_data)\n",
    "    mod.fit(X)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train_class = 5\n",
    "num_unseen_class =1\n",
    "best_lsa_model = BGMM_fits(input_data=lsa_result, max_comp=num_train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IDP Model Parameters based on BIC <bound method BayesianGaussianMixture.get_params of BayesianGaussianMixture(covariance_prior=None, covariance_type='full',\n",
      "            degrees_of_freedom_prior=None, init_params='random',\n",
      "            max_iter=1500, mean_precision_prior=0.8, mean_prior=None,\n",
      "            n_components=5, n_init=1, random_state=0, reg_covar=0,\n",
      "            tol=0.001, verbose=0, verbose_interval=10, warm_start=False,\n",
      "            weight_concentration_prior=None,\n",
      "            weight_concentration_prior_type='dirichlet_process')>\n"
     ]
    }
   ],
   "source": [
    "print \"Best IDP Model Parameters based on BIC\", best_lsa_model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.039\n",
      "Completeness: 0.042\n",
      "V-measure: 0.041\n",
      "Adjusted Rand-Index: 0.034\n",
      "Silhouette Coefficient: 0.082\n",
      "fowlkes_mallows_score: 0.243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  526.,     0.,  1022.,     0.,     0.,   693.,     0.,   672.,\n",
       "            0.,   210.]),\n",
       " array([ 0. ,  0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb28051a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_cluster = best_lsa_model.predict(lsa_result)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(df['label'], predicted_cluster))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(df['label'], predicted_cluster))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(df['label'], predicted_cluster))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(df['label'], predicted_cluster))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(lsa_result, predicted_cluster, sample_size=1000))\n",
    "print (\"fowlkes_mallows_score: %.3f\"\n",
    "      % metrics.fowlkes_mallows_score(df['label'], predicted_cluster))\n",
    "plt.hist(predicted_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_cluster_comp(predicted_labels,actual_labels):\n",
    "    Cluster_ids = {}\n",
    "    for i in predicted_labels:\n",
    "        Cluster_ids[i] = (predicted_labels==i).nonzero()[0]\n",
    "\n",
    "    targets = np.array(actual_labels)\n",
    "    #print Cluster_ids\n",
    "    for label in Cluster_ids.keys():\n",
    "        #print type(label)\n",
    "        idx = Cluster_ids[label]\n",
    "        print \"Cluster Number\", str(label), \"Composition\", np.bincount(targets[idx])\n",
    "        print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Number 0 Composition [  0  49  66 206  67 138]\n",
      "\n",
      "\n",
      "Cluster Number 1 Composition [  0 296 261 120 243 102]\n",
      "\n",
      "\n",
      "Cluster Number 2 Composition [  0 118  99 153 119 204]\n",
      "\n",
      "\n",
      "Cluster Number 3 Composition [  0 133 160  91 156 132]\n",
      "\n",
      "\n",
      "Cluster Number 4 Composition [ 0 31 37 56 46 40]\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print print_cluster_comp(predicted_labels=predicted_cluster, actual_labels=train_final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_proba_val_labels = best_lsa_model.predict_proba(lsa_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.16162119e-002   1.28062290e-016   9.78383788e-001   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  2.59465927e-009   3.32383973e-002   9.66761600e-001   8.77586817e-183\n",
      "    0.00000000e+000]\n",
      " [  1.92638968e-048   9.62230093e-011   1.00000000e+000   1.94885320e-275\n",
      "    0.00000000e+000]\n",
      " ..., \n",
      " [  1.32815298e-309   2.13123480e-045   1.00000000e+000   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  1.06880333e-060   2.94741266e-018   1.00000000e+000   2.04634362e-276\n",
      "    0.00000000e+000]\n",
      " [  5.66443871e-111   3.02850433e-006   9.99996971e-001   0.00000000e+000\n",
      "    0.00000000e+000]]\n",
      "[  1.00000000e+00   1.00000000e+00   1.00000000e+00   8.56879296e-11\n",
      "   1.00000000e+00]\n",
      "[[  2.16162119e-002   1.28062290e-016   9.78383788e-001   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  2.59465927e-009   3.32383973e-002   9.66761600e-001   1.02416621e-172\n",
      "    0.00000000e+000]\n",
      " [  1.92638968e-048   9.62230093e-011   1.00000000e+000   2.27436140e-265\n",
      "    0.00000000e+000]\n",
      " ..., \n",
      " [  1.32815298e-309   2.13123480e-045   1.00000000e+000   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  1.06880333e-060   2.94741266e-018   1.00000000e+000   2.38813522e-266\n",
      "    0.00000000e+000]\n",
      " [  5.66443871e-111   3.02850433e-006   9.99996971e-001   0.00000000e+000\n",
      "    0.00000000e+000]]\n"
     ]
    }
   ],
   "source": [
    "print pred_proba_val_labels\n",
    "val_gmm_class_max_prob_lists = np.array([max(pred_proba_val_labels[:,val]) for val in range(len(pred_proba_val_labels[0]))])\n",
    "val_gmm_class_min_prob_lists = np.array([min(pred_proba_val_labels[:,val]) for val in range(len(pred_proba_val_labels[0]))])\n",
    "val_gmm_delta = val_gmm_class_max_prob_lists - val_gmm_class_min_prob_lists\n",
    "\n",
    "print val_gmm_delta\n",
    "# Normalized for test vector\n",
    "scaled_bgmm_val_class_probs = np.divide(pred_proba_val_labels,val_gmm_delta)\n",
    "print scaled_bgmm_val_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb24147450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(pred_proba_val_labels, axis = 1)\n",
    "#print pred_proba_test_labels[:,0]\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.07392203e-10   9.99883727e-01   1.00000000e+00   8.48929437e-96\n",
      "   0.00000000e+00]\n",
      "[[  2.16162119e-002   1.28062290e-016   9.78383788e-001   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  2.59465927e-009   3.32383973e-002   9.66761600e-001   1.02416621e-172\n",
      "    0.00000000e+000]\n",
      " [  1.92638968e-048   9.62230093e-011   1.00000000e+000   2.27436140e-265\n",
      "    0.00000000e+000]\n",
      " ..., \n",
      " [  1.32815298e-309   2.13123480e-045   1.00000000e+000   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  1.06880333e-060   2.94741266e-018   1.00000000e+000   2.38813522e-266\n",
      "    0.00000000e+000]\n",
      " [  5.66443871e-111   3.02850433e-006   9.99996971e-001   0.00000000e+000\n",
      "    0.00000000e+000]]\n",
      "[[1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " ..., \n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[ 0  1  2  3  4  5  6  7  9 10]\n"
     ]
    }
   ],
   "source": [
    "class_threshold = 85.0\n",
    "val_bgmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_bgmm_val_class_probs[:,val], class_threshold) \n",
    "                                     for val in range(len(scaled_bgmm_val_class_probs[0]))])\n",
    "\n",
    "print val_bgmm_class_prob_percentile_cutoff\n",
    "\n",
    "bgmm_val_class_preds = np.greater_equal(scaled_bgmm_val_class_probs,val_bgmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "print scaled_bgmm_val_class_probs\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "val_bgmm_valid_class_probs = np.multiply(scaled_bgmm_val_class_probs, bgmm_val_class_preds)\n",
    "val_bgmm_valid_class = np.greater_equal(np.ceil(val_bgmm_valid_class_probs),1).astype(int)\n",
    "print val_bgmm_valid_class\n",
    "val_bgmm_predicted_multinomial = np.multiply(val_bgmm_valid_class, np.unique(train_final_labels))\n",
    "print np.unique(np.sum(val_bgmm_predicted_multinomial, axis=1))\n",
    "bgmm_predicted_val_class = np.max(val_bgmm_predicted_multinomial,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163 164 152 157 158 142] [342  69 107 277 103  38]\n",
      "936 936\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(valid_final_labels), np.bincount(gmm_predicted_val_class)\n",
    "print np.sum(np.bincount(valid_final_labels)), np.sum(np.bincount(gmm_predicted_val_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Unseen Class Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composition of bgmm_predicted_valid_class for true unseen class indices [53 16 10 64 10 10]\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "print \"Composition of bgmm_predicted_valid_class for true unseen class indices\", np.bincount(sorted(bgmm_predicted_val_class[missing_class_idx_val]))\n",
    "print sum(np.bincount(sorted(gmm_predicted_val_class[missing_class_idx_val])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.15      0.21       342\n",
      "          1       0.06      0.14      0.09        69\n",
      "          2       0.07      0.09      0.08       107\n",
      "          3       0.28      0.16      0.20       277\n",
      "          4       0.11      0.17      0.14       103\n",
      "          5       0.04      0.16      0.07        38\n",
      "\n",
      "avg / total       0.23      0.15      0.17       936\n",
      "\n",
      "[[53 62 46 54 74 53]\n",
      " [16 10  3 11 22  7]\n",
      " [10 36 10 32  7 12]\n",
      " [64 42 75 44 31 21]\n",
      " [10 12  6 14 18 43]\n",
      " [10  2 12  2  6  6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "print classification_report(bgmm_predicted_val_class, valid_final_labels)\n",
    "print confusion_matrix(bgmm_predicted_val_class, valid_final_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.154970760234 0.325153374233 0.209900990099\n"
     ]
    }
   ],
   "source": [
    "def calculate_unseen_class_f1score(pred_class, true_class, unseen_class_id):\n",
    "    predicted_zero_ind = (pred_class==unseen_class_id).nonzero()[0]\n",
    "    predicted_nonzero_ind = (pred_class >unseen_class_id).nonzero()[0]\n",
    "    #print np.bincount(true_class[predicted_zero_ind])[0]\n",
    "    TP = np.bincount(true_class[predicted_zero_ind])[0]\n",
    "    FP =  sum(np.bincount(true_class[predicted_zero_ind])) - TP\n",
    "    FN =  np.bincount(true_class[predicted_nonzero_ind])[0]\n",
    "    #print TP, FP, FN\n",
    "    unseen_class_precision = float(TP)/(TP+FP)\n",
    "    unseen_class_recall = float(TP)/(TP+FN)\n",
    "    unseen_class_f1 = 2*unseen_class_precision*unseen_class_recall/(unseen_class_precision+unseen_class_recall)\n",
    "    #print unseen_class_precision,unseen_class_recall,unseen_class_f1\n",
    "    return unseen_class_precision, unseen_class_recall,unseen_class_f1\n",
    "    \n",
    "pr,re,f1 = calculate_unseen_class_f1score(bgmm_predicted_val_class,valid_final_labels,0)\n",
    "print pr,re,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold Too Low. No unseen class prediction\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  56 F1 Score:  0.0228571428571\n",
      "Actual Unseen Class 163 Predicted Unseen Class 12\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  57 F1 Score:  0.0333333333333\n",
      "Actual Unseen Class 163 Predicted Unseen Class 17\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  58 F1 Score:  0.0315789473684\n",
      "Actual Unseen Class 163 Predicted Unseen Class 27\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  59 F1 Score:  0.0408163265306\n",
      "Actual Unseen Class 163 Predicted Unseen Class 33\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  60 F1 Score:  0.0574162679426\n",
      "Actual Unseen Class 163 Predicted Unseen Class 46\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  61 F1 Score:  0.0990990990991\n",
      "Actual Unseen Class 163 Predicted Unseen Class 59\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  62 F1 Score:  0.125\n",
      "Actual Unseen Class 163 Predicted Unseen Class 77\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  63 F1 Score:  0.120967741935\n",
      "Actual Unseen Class 163 Predicted Unseen Class 85\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  64 F1 Score:  0.129770992366\n",
      "Actual Unseen Class 163 Predicted Unseen Class 99\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  65 F1 Score:  0.144927536232\n",
      "Actual Unseen Class 163 Predicted Unseen Class 113\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  66 F1 Score:  0.149659863946\n",
      "Actual Unseen Class 163 Predicted Unseen Class 131\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  67 F1 Score:  0.16077170418\n",
      "Actual Unseen Class 163 Predicted Unseen Class 148\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  68 F1 Score:  0.164634146341\n",
      "Actual Unseen Class 163 Predicted Unseen Class 165\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  69 F1 Score:  0.157434402332\n",
      "Actual Unseen Class 163 Predicted Unseen Class 180\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  70 F1 Score:  0.168539325843\n",
      "Actual Unseen Class 163 Predicted Unseen Class 193\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  71 F1 Score:  0.181318681319\n",
      "Actual Unseen Class 163 Predicted Unseen Class 201\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  72 F1 Score:  0.176943699732\n",
      "Actual Unseen Class 163 Predicted Unseen Class 210\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  73 F1 Score:  0.177545691906\n",
      "Actual Unseen Class 163 Predicted Unseen Class 220\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  74 F1 Score:  0.178571428571\n",
      "Actual Unseen Class 163 Predicted Unseen Class 229\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  75 F1 Score:  0.176322418136\n",
      "Actual Unseen Class 163 Predicted Unseen Class 234\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  76 F1 Score:  0.177777777778\n",
      "Actual Unseen Class 163 Predicted Unseen Class 242\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  77 F1 Score:  0.177884615385\n",
      "Actual Unseen Class 163 Predicted Unseen Class 253\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  78 F1 Score:  0.178403755869\n",
      "Actual Unseen Class 163 Predicted Unseen Class 263\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  79 F1 Score:  0.181395348837\n",
      "Actual Unseen Class 163 Predicted Unseen Class 267\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  80 F1 Score:  0.190476190476\n",
      "Actual Unseen Class 163 Predicted Unseen Class 278\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  81 F1 Score:  0.202643171806\n",
      "Actual Unseen Class 163 Predicted Unseen Class 291\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  82 F1 Score:  0.198704103672\n",
      "Actual Unseen Class 163 Predicted Unseen Class 300\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  83 F1 Score:  0.205450733753\n",
      "Actual Unseen Class 163 Predicted Unseen Class 314\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  84 F1 Score:  0.212244897959\n",
      "Actual Unseen Class 163 Predicted Unseen Class 327\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  85 F1 Score:  0.209900990099\n",
      "Actual Unseen Class 163 Predicted Unseen Class 342\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  86 F1 Score:  0.208897485493\n",
      "Actual Unseen Class 163 Predicted Unseen Class 354\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  87 F1 Score:  0.206766917293\n",
      "Actual Unseen Class 163 Predicted Unseen Class 369\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  88 F1 Score:  0.209174311927\n",
      "Actual Unseen Class 163 Predicted Unseen Class 382\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  89 F1 Score:  0.203571428571\n",
      "Actual Unseen Class 163 Predicted Unseen Class 397\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  90 F1 Score:  0.201039861352\n",
      "Actual Unseen Class 163 Predicted Unseen Class 414\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  91 F1 Score:  0.207011686144\n",
      "Actual Unseen Class 163 Predicted Unseen Class 436\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  92 F1 Score:  0.211878009631\n",
      "Actual Unseen Class 163 Predicted Unseen Class 460\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  93 F1 Score:  0.214953271028\n",
      "Actual Unseen Class 163 Predicted Unseen Class 479\n",
      "[0 1 2 3 4 5] [0 1 2 3 4 5]\n",
      "Threshold:  94 F1 Score:  0.212121212121\n",
      "Actual Unseen Class 163 Predicted Unseen Class 497\n",
      "Best Threshold:  68\n",
      "Best F1 Score:  0.164634146341\n"
     ]
    }
   ],
   "source": [
    "best_threshold = 0.0\n",
    "best_f1_score=0.0\n",
    "for threshold in range(50,95):\n",
    "    try:\n",
    "        val_bgmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_bgmm_val_class_probs[:,val], float(threshold)) \n",
    "                                             for val in range(len(scaled_bgmm_val_class_probs[0]))])\n",
    "\n",
    "        #print val_gmm_class_prob_percentile_cutoff\n",
    "\n",
    "        bgmm_val_class_preds = np.greater_equal(scaled_bgmm_val_class_probs,val_bgmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "        #print scaled_gmm_val_class_probs\n",
    "        # Predict the test label based on percental\n",
    "        # If a data is below 80% for prob of all class, it belongs to open class\n",
    "        val_bgmm_valid_class_probs_dup = np.multiply(scaled_bgmm_val_class_probs, bgmm_val_class_preds)\n",
    "\n",
    "        val_bgmm_valid_class_max_probs = np.max(val_bgmm_valid_class_probs_dup, axis=1)\n",
    "        #print gmm_valid_class_max_probs\n",
    "        #print type(gmm_valid_class_probs_dup),  type(gmm_valid_class_max_probs)\n",
    "        val_temp = np.equal(val_bgmm_valid_class_probs_dup , val_bgmm_valid_class_max_probs.reshape(len(val_bgmm_valid_class_max_probs),1))\n",
    "        val_bgmm_valid_class_probs=np.multiply(val_bgmm_valid_class_probs_dup,val_temp)\n",
    "        val_bgmm_valid_class = np.greater_equal(np.ceil(val_bgmm_valid_class_probs),1).astype(int)\n",
    "        #print val_gmm_valid_class\n",
    "        val_bgmm_predicted_multinomial = np.multiply(val_bgmm_valid_class, np.unique(train_final_labels))\n",
    "        #print np.unique(np.sum(val_gmm_predicted_multinomial, axis=1))\n",
    "        bgmm_predicted_val_class = np.max(val_bgmm_predicted_multinomial,axis=1)  \n",
    "        print np.unique(bgmm_predicted_val_class), np.unique(valid_final_labels)\n",
    "        pr,re,f1 = calculate_unseen_class_f1score(bgmm_predicted_val_class,valid_final_labels,0)\n",
    "        print \"Threshold: \",threshold, \"F1 Score: \", f1 \n",
    "        print \"Actual Unseen Class\", np.bincount(valid_final_labels)[0], \"Predicted Unseen Class\",np.bincount(bgmm_predicted_val_class)[0]\n",
    "        # Set the threshold so that not unseen class volume is actual unseen class volume in validation set\n",
    "        unseen_class_ratio = float(np.bincount(bgmm_predicted_val_class)[0])/np.bincount(valid_final_labels)[0]\n",
    "        #overall_F1_score = f1_score(gmm_predicted_val_class, valid_final_labels)\n",
    "        if f1 > best_f1_score and unseen_class_ratio < 1.1:\n",
    "\n",
    "            best_f1_score = f1\n",
    "            best_threshold = threshold\n",
    "    except:\n",
    "        print \"Threshold Too Low. No unseen class prediction\"\n",
    "        \n",
    "print \"Best Threshold: \", best_threshold\n",
    "print \"Best F1 Score: \", best_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_proba_test_labels = best_lsa_model.predict_proba(lsa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.39403876e-077   3.29648900e-012   1.00000000e+000   5.11419065e-312\n",
      "    0.00000000e+000]\n",
      " [  1.48076963e-138   1.00000000e+000   6.82226580e-016   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  1.00000000e+000   1.35125860e-012   4.19030236e-011   3.50727026e-219\n",
      "    0.00000000e+000]\n",
      " ..., \n",
      " [  5.59944568e-015   9.99993877e-001   6.12286349e-006   1.43802132e-085\n",
      "    0.00000000e+000]\n",
      " [  1.98403048e-162   8.92519287e-016   1.00000000e+000   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  1.48116502e-038   1.00000000e+000   1.54980749e-017   1.23834906e-175\n",
      "    0.00000000e+000]]\n",
      "[  1.00000000e+00   1.00000000e+00   1.00000000e+00   2.71853572e-18\n",
      "   1.00000000e+00]\n",
      "[[  7.39403876e-077   3.29648900e-012   1.00000000e+000   1.88122989e-294\n",
      "    0.00000000e+000]\n",
      " [  1.48076963e-138   1.00000000e+000   6.82226580e-016   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  1.00000000e+000   1.35125860e-012   4.19030236e-011   1.29013212e-201\n",
      "    0.00000000e+000]\n",
      " ..., \n",
      " [  5.59944568e-015   9.99993877e-001   6.12286349e-006   5.28969072e-068\n",
      "    0.00000000e+000]\n",
      " [  1.98403048e-162   8.92519287e-016   1.00000000e+000   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  1.48116502e-038   1.00000000e+000   1.54980749e-017   4.55520612e-158\n",
      "    0.00000000e+000]]\n"
     ]
    }
   ],
   "source": [
    "print pred_proba_test_labels\n",
    "bgmm_class_max_prob_lists = np.array([max(pred_proba_test_labels[:,val]) for val in range(len(pred_proba_test_labels[0]))])\n",
    "bgmm_class_min_prob_lists = np.array([min(pred_proba_test_labels[:,val]) for val in range(len(pred_proba_test_labels[0]))])\n",
    "bgmm_delta = bgmm_class_max_prob_lists - bgmm_class_min_prob_lists\n",
    "\n",
    "print bgmm_delta\n",
    "# Normalized for test vector\n",
    "scaled_bgmm_test_class_probs = np.divide(pred_proba_test_labels,bgmm_delta)\n",
    "print scaled_bgmm_test_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdab3505a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.amax(pred_proba_test_labels, axis = 1)\n",
    "#print pred_proba_test_labels[:,0]\n",
    "plt.figure(figsize = (12, 8))\n",
    "n, bins, patches = plt.hist(x, 50)\n",
    "plt.title(\"max prob dist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "[[  0.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  0.00000000e+000   1.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  1.00000000e+000   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " ..., \n",
      " [  5.59944568e-015   9.99993877e-001   0.00000000e+000   5.28969072e-068\n",
      "    0.00000000e+000]\n",
      " [  0.00000000e+000   0.00000000e+000   1.00000000e+000   0.00000000e+000\n",
      "    0.00000000e+000]\n",
      " [  0.00000000e+000   1.00000000e+000   0.00000000e+000   4.55520612e-158\n",
      "    0.00000000e+000]]\n",
      "[ 0.          1.          1.         ...,  0.99999388  1.          1.        ]\n",
      "[[0 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " ..., \n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]]\n",
      "[0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print best_threshold\n",
    "bgmm_class_prob_percentile_cutoff = np.array([np.percentile(scaled_bgmm_test_class_probs[:,val], best_threshold) \n",
    "                                     for val in range(len(scaled_bgmm_test_class_probs[0]))])\n",
    "\n",
    "#print gmm_class_prob_percentile_cutoff\n",
    "\n",
    "bgmm_test_class_preds = np.greater_equal(scaled_bgmm_test_class_probs,bgmm_class_prob_percentile_cutoff).astype(int)\n",
    "\n",
    "#print scaled_gmm_test_class_probs\n",
    "# Predict the test label based on percental\n",
    "# If a data is below 80% for prob of all class, it belongs to open class\n",
    "bgmm_valid_class_probs_dup = np.multiply(scaled_bgmm_test_class_probs, bgmm_test_class_preds)\n",
    "print bgmm_valid_class_probs_dup\n",
    "bgmm_valid_class_max_probs = np.max(bgmm_valid_class_probs_dup, axis=1)\n",
    "print bgmm_valid_class_max_probs\n",
    "#print type(gmm_valid_class_probs_dup),  type(gmm_valid_class_max_probs)\n",
    "temp = np.equal(bgmm_valid_class_probs_dup , bgmm_valid_class_max_probs.reshape(len(bgmm_valid_class_max_probs),1))\n",
    "bgmm_valid_class_probs=np.multiply(bgmm_valid_class_probs_dup,temp)\n",
    "bgmm_valid_class = np.greater_equal(np.ceil(bgmm_valid_class_probs),1).astype(int)\n",
    "print bgmm_valid_class\n",
    "bgmm_predicted_multinomial = np.multiply(bgmm_valid_class, np.unique(train_final_labels))\n",
    "print np.unique(np.sum(bgmm_predicted_multinomial, axis=1))\n",
    "bgmm_predicted_test_class = np.max(bgmm_predicted_multinomial,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202 191 188 205 202 182] [204 134 369 375  22  66]\n",
      "1170 1170\n",
      "[[22 39 50 77  2 12]\n",
      " [47 12 70 50  3  9]\n",
      " [44  7 46 74  2 15]\n",
      " [29 26 63 77  3  7]\n",
      " [33 23 65 64  6 11]\n",
      " [29 27 75 33  6 12]]\n"
     ]
    }
   ],
   "source": [
    "print np.bincount(test_labels), np.bincount(bgmm_predicted_test_class)\n",
    "print np.sum(np.bincount(test_labels)), np.sum(np.bincount(bgmm_predicted_test_class))\n",
    "print confusion_matrix(test_labels, bgmm_predicted_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.13      0.14       202\n",
      "          1       0.17      0.07      0.10       191\n",
      "          2       0.14      0.23      0.18       188\n",
      "          3       0.36      0.29      0.32       205\n",
      "          4       0.16      0.25      0.20       202\n",
      "          5       0.43      0.29      0.35       182\n",
      "\n",
      "avg / total       0.23      0.21      0.21      1170\n",
      "\n",
      "0.211111111111\n"
     ]
    }
   ],
   "source": [
    "print classification_report(test_labels, gmm_predicted_test_class)\n",
    "print accuracy_score(test_labels, gmm_predicted_test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen Class Precision, Recall F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Class Precision:  0.107843137255\n",
      "Unseen Class Recall:  0.108910891089\n",
      "Unseen Class F1 Score:  0.108374384236\n"
     ]
    }
   ],
   "source": [
    "print \"Unseen Class Precision: \", calculate_unseen_class_f1score(bgmm_predicted_test_class,test_labels,0)[0]\n",
    "print \"Unseen Class Recall: \", calculate_unseen_class_f1score(bgmm_predicted_test_class,test_labels,0)[1]\n",
    "print \"Unseen Class F1 Score: \", calculate_unseen_class_f1score(bgmm_predicted_test_class,test_labels,0)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.054\n",
      "Completeness: 0.057\n",
      "V-measure: 0.055\n",
      "Adjusted Rand-Index: 0.030\n",
      "Silhouette Coefficient: 0.025\n",
      "fowlkes_mallows_score: 0.206\n"
     ]
    }
   ],
   "source": [
    "pred_class_indices = (gmm_predicted_test_class==0).nonzero()[0]\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(df_test['label'], gmm_predicted_test_class))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(lsa_test, gmm_predicted_test_class, sample_size=1000))\n",
    "print (\"fowlkes_mallows_score: %.3f\"\n",
    "      % metrics.fowlkes_mallows_score(df_test['label'], gmm_predicted_test_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
